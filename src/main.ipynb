{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8179d327",
   "metadata": {},
   "source": [
    "# <span style='color:Tomato;'>Load Env Variables</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3c5816f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Directory: /DATA/Ali_Data/GraphRAG-Neo4j-VMD-NAMD\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "import utils\n",
    "\n",
    "# Add the modules directory to the Python path if needed\n",
    "# sys.path.append(os.path.abspath(\"./modules\"))\n",
    "\n",
    "# load variables into env\n",
    "root_dir = utils.get_project_root()\n",
    "f = root_dir / \".secrets\" / \".env\"\n",
    "assert f.exists(), f\"File not found: {f}\"\n",
    "dotenv.load_dotenv(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61b8b91",
   "metadata": {},
   "source": [
    "# <span style='color:Tomato;'>Process PDFs</span>\n",
    "\n",
    "We'll use Langchain `PyMuPDF4LLM` to load the PDF files into LangChain documents.\n",
    "\n",
    "We'll also use LLM to convert images into a summery and extract its data.\n",
    "\n",
    "\n",
    "## <span style='color:Orange;'>Basic Imports</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e74d0d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "from copy import copy\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from time import localtime, strftime\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf5e7cb",
   "metadata": {},
   "source": [
    "## <span style='color:Orange;'>Loading PDF file as LangChain Document</span>\n",
    "\n",
    "> Images will be extracted (to text) using a Multimodal LLM.\n",
    "\n",
    "You can either use `load()` method to do it all at once in memory or inclemently do it using `lazy_load()`.\n",
    "\n",
    "Since our docs are big, we'll use `lazy_load()` to also see the progress.\n",
    "\n",
    "To save time, we will load the docs from a pickle file if previously processed, otherwise process them and save them as a pickle.\n",
    "\n",
    "### <span style='color:Khaki;'>Custom Splitting Mode</span>\n",
    "\n",
    "> By default, each page in the PDF is a (LangChain) Document!\n",
    "\n",
    "When loading the PDF file you can split it in two different ways:\n",
    "- By page `mode=\"page\"`\n",
    "- As a single text flow `mode=\"single\"`. In other words, the whole PDF would be **one** LangChain Document. You can specify page delimiter to have the pages in the metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6c23482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_filename_len(file_path: Path, page_delimiter=None) -> tuple[str, int]:\n",
    "    \"\"\"\n",
    "    Update the filename length for the given file path.\n",
    "    :param file_path: The file path to update.\n",
    "    :return: A tuple containing the updated file name and its length.\n",
    "    \"\"\"\n",
    "    file_name = file_path.stem.lower()\n",
    "    with fitz.open(file_path) as pdf_doc:\n",
    "        if page_delimiter is not None:\n",
    "            # use regex to look for the number of page delimiter in the file contents\n",
    "            file_len = len([page for page in pdf_doc if page_delimiter in page.get_text(\"text\").lower()])\n",
    "        else:\n",
    "            file_len = len(pdf_doc)\n",
    "    return file_name, file_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'biopython' not found. Fuzzy Searching ...\n",
      "file_path = /DATA/Ali_Data/GraphRAG-Neo4j-VMD-NAMD/data/pdfs/BioPython.pdf\n"
     ]
    }
   ],
   "source": [
    "# pdf file\n",
    "file_path = Path() / \"..\" / \"data\" / \"pdfs\" / \"biopython.pdf\"\n",
    "\n",
    "file_path = file_path.resolve()\n",
    "file_path = utils.fuzzy_find(file_path)\n",
    "\n",
    "file_name, file_len = update_filename_len(file_path)\n",
    "\n",
    "# create directory for pkl files\n",
    "pkl_dir = file_path.parent.parent / \"pkls\"\n",
    "pkl_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(f\"file_path = {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "308b5274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "file_path = /DATA/Ali_Data/GraphRAG-Neo4j-VMD-NAMD/data/pdfs/BioPython.pdf\n"
     ]
    }
   ],
   "source": [
    "# if a problem occurs during the loading, use this to delete previously processed pages.\n",
    "# todo: the page numbers are reindexed to zero\n",
    "\n",
    "problematic_pages = []\n",
    "range_to_keep = range(0, 55)  # 391 to 445 (exclusive)\n",
    "\n",
    "if False:\n",
    "    import tempfile\n",
    "\n",
    "    temp_dir = Path(tempfile.mkdtemp())\n",
    "    display(Markdown(\"#### <span style='color:orangered;'>Warning: Deleting Pages !!!</span>\"))\n",
    "    temp_dir = Path(tempfile.mkdtemp()) if not isinstance(temp_dir, Path) else temp_dir\n",
    "    temp_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    with fitz.open(file_path) as doc:\n",
    "        # PART I: extract deleted pages\n",
    "        if len(problematic_pages) > 0:\n",
    "            range_to_keep = list(set(range_to_keep) - set(problematic_pages))  # needed for next part\n",
    "\n",
    "            temp_doc = fitz.open()\n",
    "            for page_number in problematic_pages:\n",
    "                temp_doc.insert_pdf(doc, from_page=page_number, to_page=page_number)\n",
    "\n",
    "            extract_file_path = temp_dir / f\"{file_name}_extract.pdf\"\n",
    "            temp_doc.save(extract_file_path)\n",
    "            temp_doc.close()\n",
    "            \n",
    "            print(f\"extract_file_path = {extract_file_path}\")\n",
    "\n",
    "        # ========================================================\n",
    "        # PART II: extract pages to keep\n",
    "        doc.select(range_to_keep)\n",
    "        partial_file_path = temp_dir / f\"{file_name}_partial.pdf\"\n",
    "        doc.save(partial_file_path)\n",
    "    \n",
    "    print(f\"partial_file_path = {partial_file_path}\")\n",
    "\n",
    "print(f\"\\nfile_path = {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7ab061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test if the correct pages are extracted\n",
    "# with fitz.open(partial_file_path) as doc:\n",
    "#     print(doc[0].get_textpage().extractText())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b22254",
   "metadata": {},
   "source": [
    "#### <span style='color:LightGreen;'>How the Asynchronous Lazy Loading Loop</span>\n",
    "\n",
    "This code demonstrates an asynchronous lazy loading pattern with a progress bar. Let me explain how it works:\n",
    "\n",
    "\n",
    "##### <span style='color:SkyBlue;'>Key Components</span>\n",
    "\n",
    "1. `alazy_load()` - An asynchronous generator that yields documents one by one\n",
    "2. `async for` - Asynchronous iteration through the generator\n",
    "3. `tqdm.tqdm()` - Progress bar visualization\n",
    "4. Batching logic to process documents in chunks of 100\n",
    "\n",
    "##### <span style='color:SkyBlue;'>How the Async Loop Works</span>\n",
    "\n",
    "```python\n",
    "async for doc in tqdm.tqdm(await loader.alazy_load()):\n",
    "    # Process each document as it becomes available\n",
    "```\n",
    "\n",
    "The `await loader.alazy_load()` returns an asynchronous iterable. The `async for` loop then:\n",
    "\n",
    "1. Asynchronously requests the next document\n",
    "2. Waits for it to be retrieved without blocking the event loop\n",
    "3. Updates the progress bar via `tqdm`\n",
    "4. Processes the document once available\n",
    "\n",
    "The batching logic (collecting 100 pages before processing) allows for more efficient operations on groups of documents rather than one at a time.\n",
    "\n",
    "This pattern is especially useful when loading documents involves network requests or other I/O operations that would otherwise block execution.\n",
    "\n",
    "\n",
    "### <span style='color:Khaki;'>LLM Prompt</span>\n",
    "\n",
    "> You are an assistant tasked with summarizing images for retrieval.\n",
    "> 1. These summaries will be embedded and used to retrieve the raw image.\n",
    ">    Give a concise summary of the image that is well optimized for retrieval\n",
    "> 2. extract all the text from the image. Do not exclude any content from the page.\n",
    "> Format answer in markdown without explanatory text and without markdown delimiter ``` at the beginning.\n",
    "\n",
    "\n",
    "### <span style='color:Khaki;'>Which LLM to use?</span>\n",
    "\n",
    "- `gemma3:4b`: **biggest,** but provide a general understanding of the images.\n",
    "- `granite3.2-vision`: **small,** and fine-tunned for data extraction from images in PDF docs.\n",
    "- `moondream`: **smallest,** but only good for overall description of the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f86838d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                        ID              SIZE      MODIFIED    \n",
      "nomic-embed-text:latest     0a109f422b47    274 MB    2 days ago     \n",
      "llama3.2:latest             a80c4f17acd5    2.0 GB    3 days ago     \n",
      "smollm2:latest              cef4a1e09247    1.8 GB    3 days ago     \n",
      "bge-m3:latest               790764642607    1.2 GB    6 days ago     \n",
      "moondream:latest            55fc3abd3867    1.7 GB    10 days ago    \n",
      "granite3.2-vision:latest    3be41a661804    2.4 GB    10 days ago    \n",
      "gemma3:4b                   a2af6cc3eb7f    3.3 GB    10 days ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "beac619d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pfile_name='biopython' -> 445 pages\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders.parsers import LLMImageBlobParser\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_pymupdf4llm import PyMuPDF4LLMLoader\n",
    "\n",
    "pfile_path = file_path\n",
    "extract_images = True\n",
    "\n",
    "pfile_name, pfile_len = update_filename_len(pfile_path)\n",
    "\n",
    "if extract_images:\n",
    "    loader = PyMuPDF4LLMLoader(\n",
    "        pfile_path,\n",
    "        mode=\"page\",  # page | single\n",
    "        extract_images=True,\n",
    "        images_parser=LLMImageBlobParser(model=ChatOllama(model=\"granite3.2-vision\", max_tokens=1024)),\n",
    "    )\n",
    "else:\n",
    "    loader = PyMuPDF4LLMLoader(pfile_path, mode=\"page\")\n",
    "\n",
    "print(f\"{pfile_name=} -> {pfile_len} pages\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437a28c9",
   "metadata": {},
   "source": [
    "The nice thing about `lazy_load()`, is that we can stop processing any page and skip it if a problem happen.\n",
    "\n",
    "You can also resume whenever you want or process pages with different config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44fa7a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading docs from pickle\n",
      "Loaded biopython: 445 documents\n"
     ]
    }
   ],
   "source": [
    "pkl_name = pkl_dir / f\"docs_pages_{pfile_name}.pkl\"\n",
    "\n",
    "if pkl_name.exists():\n",
    "    print(\"Loading docs from pickle\")\n",
    "    with open(pkl_name, \"rb\") as f:\n",
    "        docs = pickle.load(f)\n",
    "else:\n",
    "    docs = []\n",
    "    try:\n",
    "        print(\n",
    "            f\"Loading docs from pdf. \\nThis will take some time (~{int(pfile_len / 30)} min)\"\n",
    "        )  # on average 30 pages per minute\n",
    "\n",
    "        # Option 1: loading small docs\n",
    "        # docs = loader.load()\n",
    "\n",
    "        # ---------------------------\n",
    "\n",
    "        # Option 2: Load documents asynchronously (almost 3x faster)\n",
    "        # assert not extract_images, \"Async loading not supported for image extraction\"\n",
    "        # docs = await loader.aload()\n",
    "\n",
    "        # ---------------------------\n",
    "\n",
    "        # Option 3: lazy load with progress bar\n",
    "        # # todo: make this asynchronous\n",
    "\n",
    "        for doc in tqdm(loader.lazy_load(), total=pfile_len):\n",
    "            docs.append(doc)\n",
    "\n",
    "        # pickle save the docs\n",
    "        with open(pkl_name, \"wb\") as f:\n",
    "            pickle.dump(docs, f)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{len(docs)=}\")\n",
    "        tname = pkl_name.with_suffix(f\".{strftime('%m%d.%H%M%S', localtime())}.pkl\")\n",
    "        with open(tname, \"wb\") as f:\n",
    "            pickle.dump(docs, f)\n",
    "        raise e\n",
    "\n",
    "print(f\"Loaded {pfile_name}: {len(docs)} documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a8e462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # merging docs if partially processed\n",
    "# with open(pkl_dir / \"docs_w.img.biopython_part1.pkl\", \"rb\") as f:\n",
    "#     docs0 = pickle.load(f)\n",
    "\n",
    "# with open(pkl_dir / \"docs_w.img.biopython_partial.pkl\", \"rb\") as f:\n",
    "#     docs1 = pickle.load(f)\n",
    "\n",
    "# with open(pkl_dir / \"docs_biopython_extract.pkl\", \"rb\") as f:\n",
    "#     docs2 = pickle.load(f)\n",
    "\n",
    "# docs = docs0 + docs1 + docs2\n",
    "\n",
    "# print(f\"Loaded {len(docs)} documents\")\n",
    "\n",
    "# with open(pkl_dir / f\"docs_biopython.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(docs, f)\n",
    "\n",
    "# -----------------------------\n",
    "\n",
    "# # Correcting the page numbers\n",
    "# correct_pages = list(range(0, 445))\n",
    "# extract_pages = [391, 392, 395, 428]\n",
    "\n",
    "# for i in extract_pages:\n",
    "#     correct_pages.remove(i)\n",
    "# correct_pages = correct_pages + extract_pages\n",
    "\n",
    "# for d, i in zip(docs, correct_pages):\n",
    "#     d.metadata[\"page\"] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ac331c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = docs[-5]\n",
    "# display(Markdown(temp.page_content))\n",
    "# print('-'*50)\n",
    "# pprint.pp(temp.metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4e7061",
   "metadata": {},
   "source": [
    "### <span style='color:Khaki;'>Cleaning Docs</span>\n",
    "\n",
    "1. Clean the \"Contents\" section by:\n",
    "    - remove `. . .`\n",
    "    - add `page: ` before page numbers\n",
    "\n",
    "2. Remove the page numbers at the end of each doc `\\n\\n<num>\\n\\n`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca125ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe275613bf94f0db3b25e8a91fb4c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/445 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New docs: 445\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(docs, total=len(docs)):\n",
    "    txt = doc.page_content\n",
    "\n",
    "    # cleaning Content section\n",
    "    if doc.metadata[\"page\"] in range(0, 10):\n",
    "        # we use \". .\" so not to delete the end sentence dot\n",
    "        txt = txt.replace(\". .\", \"\").strip()\n",
    "\n",
    "        while txt.find(\"  \") > 0:\n",
    "            txt = txt.replace(\"  \", \" \")\n",
    "\n",
    "        txt = txt.replace(\" . \", \" \")\n",
    "        txt = re.sub(r\" (\\d+(?:\\d+)*?)\\n\", r\" page: \\1\\n\", txt)\n",
    "\n",
    "    txt = re.sub(r\"(\\n*)(\\d*)(\\n*)$\", r\"\", txt)  # remove page numbers\n",
    "\n",
    "    if txt in [\"\", \".\", \" \"]:\n",
    "        doc.metadata['empty'] = 1\n",
    "    doc.page_content = txt\n",
    "\n",
    "# delete empty docs\n",
    "docs = [doc for doc in docs if \"empty\" not in doc.metadata]\n",
    "\n",
    "print(f\"New docs: {len(docs)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff05a99",
   "metadata": {},
   "source": [
    "## <span style='color:Orange;'>Doc Chunking (Spiting)</span>\n",
    "\n",
    "We'll split text based on semantic similarity instead of character based. Inspired by the [5 Levels Of Text Splitting](https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb).\n",
    "To instantiate a [SemanticChunker](https://python.langchain.com/api_reference/experimental/text_splitter/langchain_experimental.text_splitter.SemanticChunker.html), we must specify an embedding model first.\n",
    "\n",
    "```python\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "text_splitter = SemanticChunker(EmbeddingModel())\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132709aa",
   "metadata": {},
   "source": [
    "### <span style='color:Khaki;'>Custom `EmbeddingModel` Class</span>\n",
    "\n",
    "This class must conform to the `Embeddings` interface because `SemanticChunker` expects an object that implements the `embed_documents` (or `embed_query`) methods.\n",
    "Just a standalone function `embed_content()` wonâ€™t satisfy the interface that `SemanticChunker` relies on.\n",
    "\n",
    "```python\n",
    "from langchain.embeddings.base import Embeddings\n",
    "\n",
    "class CustomEmbeddingModel(Embeddings):\n",
    "    def __init__(self, task_type=\"SEMANTIC_SIMILARITY\"):\n",
    "        self.task_type = task_type\n",
    "\n",
    "    @retry.Retry(predicate=is_retriable)  # if you have a Retry function (like Gemini)\n",
    "    def embed_documents(self, input: Documents) -> Embeddings:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input (Documents: list[str])\n",
    "\n",
    "        Returns:\n",
    "            Embeddings (list[list[float]])\n",
    "        \"\"\"\n",
    "        response = client.models.embed_content(\n",
    "            model=\"models/text-embedding-004\", contents=input, config=types.EmbedContentConfig(task_type=self.task_type)\n",
    "        )\n",
    "        return [e.values for e in response.embeddings]\n",
    "    \n",
    "    def embed_query():\n",
    "        print(\"embed_query() not implemented\")\n",
    "        return None\n",
    "\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        return self.embed_documents(input)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2192845",
   "metadata": {},
   "source": [
    "\n",
    "### <span style='color:Khaki;'>Gemmini Embeddings</span>\n",
    "\n",
    "If you use your free Google quota for embedding, it will exhaust it.\n",
    "We'll use an open source embedding for text splitting.\n",
    "\n",
    "\n",
    "```python\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from google.api_core import retry\n",
    "from langchain_google_genai.embeddings import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "print(genai.__version__)\n",
    "\n",
    "# the api is loaded from the env\n",
    "client = genai.Client()\n",
    "\n",
    "for m in client.models.list():\n",
    "    if \"embedContent\" in m.supported_actions:\n",
    "        print(m.name)\n",
    "\n",
    "# Define a helper to retry when per-minute quota is reached.\n",
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "Embedding_Model = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\", task_type=\"SEMANTIC_SIMILARITY\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbf64ff",
   "metadata": {},
   "source": [
    "### <span style='color:Khaki;'>Create Text Splitter</span>\n",
    "\n",
    "**What is the difference between `transform_documents(documents: Sequence[Document])` and `split_documents(documents: Iterable[Document])`?**\n",
    "\n",
    "`transform_documents()` is just a wrapper around `split_documents()`. So both end up producing the same split documents.\n",
    "If you already have a list of documents and just want them split, you can call `split_documents()` directly.\n",
    "If your pipeline expects a `transform_documents()` method (as defined by the `BaseDocumentTransformer` interface), use `transform_documents()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7cdf8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporary directory: /tmp/tmpy0lk29lf\n",
      "Loading split docs from pickle\n",
      "Loaded biopython: 906 documents\n"
     ]
    }
   ],
   "source": [
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "from my_langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "pkl_name = pkl_dir / f\"docs_pages_semantic_split_bgem3_{pfile_name}.pkl\"\n",
    "\n",
    "text_splitter = SemanticChunker(\n",
    "    embeddings=OllamaEmbeddings(model=\"bge-m3\"), add_start_index=True, show_progress=True, save_temp=True\n",
    ")\n",
    "\n",
    "# we'll setup a character text splitter to use if we get an exception when creating the graph\n",
    "# text_splitter_bkp = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=100)\n",
    "# docs_split = text_splitter_bkp.split_documents(documents=docs)\n",
    "\n",
    "\n",
    "if pkl_name.exists():\n",
    "    print(\"Loading split docs from pickle\")\n",
    "    with open(pkl_name, \"rb\") as f:\n",
    "        docs_split = pickle.load(f)\n",
    "else:\n",
    "    docs_split = text_splitter.split_documents(docs)\n",
    "\n",
    "    with open(pkl_name, \"wb\") as f:\n",
    "        pickle.dump(docs_split, f)\n",
    "\n",
    "print(f\"Loaded {pfile_name}: {len(docs_split)} documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0ec7cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                        ID              SIZE      MODIFIED    \n",
      "nomic-embed-text:latest     0a109f422b47    274 MB    2 days ago     \n",
      "llama3.2:latest             a80c4f17acd5    2.0 GB    3 days ago     \n",
      "smollm2:latest              cef4a1e09247    1.8 GB    3 days ago     \n",
      "bge-m3:latest               790764642607    1.2 GB    6 days ago     \n",
      "moondream:latest            55fc3abd3867    1.7 GB    10 days ago    \n",
      "granite3.2-vision:latest    3be41a661804    2.4 GB    10 days ago    \n",
      "gemma3:4b                   a2af6cc3eb7f    3.3 GB    10 days ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626b360d",
   "metadata": {},
   "source": [
    "## <span style='color:Orange;'>Graph Database</span>\n",
    "\n",
    "### <span style='color:Khaki;'>Notes</span>\n",
    "\n",
    "1. Use a bigger model such as `gemma3:4b` to parse the information as smaller models like `smollm2` get stuck.\n",
    "2. Use `jupytext` to make this into a python script and run it in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd9972f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph docs from pickle\n",
      "Loaded biopython: 908 documents\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from my_langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "\n",
    "\n",
    "pkl_name = pkl_dir / f\"docs_graph_bgem3_{pfile_name}.pkl\"\n",
    "\n",
    "if pkl_name.exists():\n",
    "    print(\"Loading graph docs from pickle\")\n",
    "    with open(pkl_name, \"rb\") as f:\n",
    "        gdocs = pickle.load(f)\n",
    "else:\n",
    "    llm = ChatOllama(model=\"gemma3:4b\", temperature=0, format=\"json\")\n",
    "    llm_transformer = LLMGraphTransformer(llm=llm, show_progress=True, pkl_path=pkl_name, force_finish=True)\n",
    "    gdocs, sdocs = llm_transformer.convert_to_graph_documents(docs_split)\n",
    "\n",
    "    with open(pkl_name, \"wb\") as f:\n",
    "        pickle.dump(gdocs, f)\n",
    "    \n",
    "    if len(sdocs) > 0:\n",
    "        with open(pkl_name.with_suffix(\".skipped.id.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(sdocs, f)\n",
    "\n",
    "print(f\"Loaded {pfile_name}: {len(gdocs)} documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f518f9c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not connect to Neo4j database. Please ensure that the url is correct",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectionRefusedError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/DATA/Ali_Data/GraphRAG-Neo4j-VMD-NAMD/.venv/lib/python3.11/site-packages/neo4j/_async_compat/network/_bolt_socket.py:409\u001b[39m, in \u001b[36mBoltSocketBase._connect_secure\u001b[39m\u001b[34m(cls, resolved_address, timeout, keep_alive, ssl_context)\u001b[39m\n\u001b[32m    408\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33m[#0000]  C: <OPEN> \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, resolved_address)\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m \u001b[43ms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    410\u001b[39m s.settimeout(t)\n",
      "\u001b[31mConnectionRefusedError\u001b[39m: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mServiceUnavailable\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/DATA/Ali_Data/GraphRAG-Neo4j-VMD-NAMD/.venv/lib/python3.11/site-packages/neo4j/_sync/io/_bolt_socket.py:328\u001b[39m, in \u001b[36mBoltSocket.connect\u001b[39m\u001b[34m(cls, address, tcp_timeout, deadline, custom_resolver, ssl_context, keep_alive)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     s = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connect_secure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresolved_address\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtcp_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mssl_context\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    331\u001b[39m     agreed_version, handshake, response = s._handshake(\n\u001b[32m    332\u001b[39m         resolved_address, deadline\n\u001b[32m    333\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/DATA/Ali_Data/GraphRAG-Neo4j-VMD-NAMD/.venv/lib/python3.11/site-packages/neo4j/_async_compat/network/_bolt_socket.py:426\u001b[39m, in \u001b[36mBoltSocketBase._connect_secure\u001b[39m\u001b[34m(cls, resolved_address, timeout, keep_alive, ssl_context)\u001b[39m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error, \u001b[38;5;167;01mOSError\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceUnavailable(\n\u001b[32m    427\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFailed to establish connection to \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    428\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_address\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m (reason \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    429\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merror\u001b[39;00m\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mServiceUnavailable\u001b[39m: Failed to establish connection to ResolvedIPv4Address(('127.0.0.1', 7687)) (reason [Errno 111] Connection refused)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mServiceUnavailable\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/DATA/Ali_Data/GraphRAG-Neo4j-VMD-NAMD/.venv/lib/python3.11/site-packages/langchain_neo4j/graphs/neo4j_graph.py:153\u001b[39m, in \u001b[36mNeo4jGraph.__init__\u001b[39m\u001b[34m(self, url, username, password, database, timeout, sanitize, refresh_schema, driver_config, enhanced_schema)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_driver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mverify_connectivity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m neo4j.exceptions.ConfigurationError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/DATA/Ali_Data/GraphRAG-Neo4j-VMD-NAMD/.venv/lib/python3.11/site-packages/neo4j/_sync/driver.py:1082\u001b[39m, in \u001b[36mDriver.verify_connectivity\u001b[39m\u001b[34m(self, **config)\u001b[39m\n\u001b[32m   1081\u001b[39m session_config = \u001b[38;5;28mself\u001b[39m._read_session_config(config)\n\u001b[32m-> \u001b[39m\u001b[32m1082\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_server_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/DATA/Ali_Data/GraphRAG-Neo4j-VMD-NAMD/.venv/lib/python3.11/site-packages/neo4j/_sync/driver.py:1297\u001b[39m, in \u001b[36mDriver._get_server_info\u001b[39m\u001b[34m(self, session_config)\u001b[39m\n\u001b[32m   1296\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._session(session_config) \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m-> \u001b[39m\u001b[32m1297\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_server_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/DATA/Ali_Data/GraphRAG-Neo4j-VMD-NAMD/.venv/lib/python3.11/site-packages/neo4j/_sync/work/session.py:183\u001b[39m, in \u001b[36mSession._get_server_info\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mREAD_ACCESS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mliveness_check_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m server_info = \u001b[38;5;28mself\u001b[39m._connection.server_info\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/DATA/Ali_Data/GraphRAG-Neo4j-VMD-NAMD/.venv/lib/python3.11/site-packages/neo4j/_sync/work/session.py:136\u001b[39m, in \u001b[36mSession._connect\u001b[39m\u001b[34m(self, access_mode, **acquire_kwargs)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccess_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43macquire_kwargs\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio.CancelledError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/DATA/Ali_Data/GraphRAG-Neo4j-VMD-NAMD/.venv/lib/python3.11/site-packages/neo4j/_sync/work/workspace.py:199\u001b[39m, in \u001b[36mWorkspace._connect\u001b[39m\u001b[34m(self, access_mode, auth, **acquire_kwargs)\u001b[39m\n\u001b[32m    198\u001b[39m acquire_kwargs_.update(acquire_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m \u001b[38;5;28mself\u001b[39m._connection = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43macquire_kwargs_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    201\u001b[39m     target_db.guessed\n\u001b[32m    202\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pinned_database\n\u001b[32m   (...)\u001b[39m\u001b[32m    206\u001b[39m     \u001b[38;5;66;03m# support SSR.\u001b[39;00m\n\u001b[32m    207\u001b[39m     \u001b[38;5;66;03m# => we need to fall back to explicit home database resolution\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/DATA/Ali_Data/GraphRAG-Neo4j-VMD-NAMD/.venv/lib/python3.11/site-packages/neo4j/_sync/io/_pool.py:662\u001b[39m, in \u001b[36mBoltPool.acquire\u001b[39m\u001b[34m(self, access_mode, timeout, database, bookmarks, auth, liveness_check_timeout, database_callback)\u001b[39m\n\u001b[32m    661\u001b[39m deadline = Deadline.from_timeout_or_deadline(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m662\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mliveness_check_timeout\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/DATA/Ali_Data/GraphRAG-Neo4j-VMD-NAMD/.venv/lib/python3.11/site-packages/neo4j/_sync/io/_pool.py:408\u001b[39m, in \u001b[36mIOPool._acquire\u001b[39m\u001b[34m(self, address, auth, deadline, liveness_check_timeout)\u001b[39m\n\u001b[32m    407\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33m[#0000]  _: <POOL> trying to hand out new connection\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m408\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/DATA/Ali_Data/GraphRAG-Neo4j-VMD-NAMD/.venv/lib/python3.11/site-packages/neo4j/_sync/io/_pool.py:230\u001b[39m, in \u001b[36mIOPool._acquire_new_later.<locals>.connection_creator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m     connection = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopener\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpool_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeadline\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ServiceUnavailable:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/DATA/Ali_Data/GraphRAG-Neo4j-VMD-NAMD/.venv/lib/python3.11/site-packages/neo4j/_sync/io/_pool.py:624\u001b[39m, in \u001b[36mBoltPool.open.<locals>.opener\u001b[39m\u001b[34m(addr, auth_manager, deadline)\u001b[39m\n\u001b[32m    623\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mopener\u001b[39m(addr, auth_manager, deadline):\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBolt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m        \u001b[49m\u001b[43maddr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mauth_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrouting_context\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/DATA/Ali_Data/GraphRAG-Neo4j-VMD-NAMD/.venv/lib/python3.11/site-packages/neo4j/_sync/io/_bolt.py:369\u001b[39m, in \u001b[36mBolt.open\u001b[39m\u001b[34m(cls, address, auth_manager, deadline, routing_context, pool_config)\u001b[39m\n\u001b[32m    367\u001b[39m     deadline = Deadline(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m s, protocol_version, handshake, data = \u001b[43mBoltSocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m    \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtcp_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnection_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_resolver\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_ssl_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m pool_config.protocol_version = protocol_version\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/DATA/Ali_Data/GraphRAG-Neo4j-VMD-NAMD/.venv/lib/python3.11/site-packages/neo4j/_sync/io/_bolt_socket.py:376\u001b[39m, in \u001b[36mBoltSocket.connect\u001b[39m\u001b[34m(cls, address, tcp_timeout, deadline, custom_resolver, ssl_context, keep_alive)\u001b[39m\n\u001b[32m    375\u001b[39m error_strs = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, errors))\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ServiceUnavailable(\n\u001b[32m    377\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt connect to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maddress\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (resolved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maddress_strs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m):\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    378\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror_strs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    379\u001b[39m ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merrors\u001b[39;00m[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mServiceUnavailable\u001b[39m: Couldn't connect to localhost:7687 (resolved to ('127.0.0.1:7687',)):\nFailed to establish connection to ResolvedIPv4Address(('127.0.0.1', 7687)) (reason [Errno 111] Connection refused)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_neo4j\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Neo4jGraph\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m graph = \u001b[43mNeo4jGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/DATA/Ali_Data/GraphRAG-Neo4j-VMD-NAMD/.venv/lib/python3.11/site-packages/langchain_neo4j/graphs/neo4j_graph.py:160\u001b[39m, in \u001b[36mNeo4jGraph.__init__\u001b[39m\u001b[34m(self, url, username, password, database, timeout, sanitize, refresh_schema, driver_config, enhanced_schema)\u001b[39m\n\u001b[32m    155\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    156\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not connect to Neo4j database. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure that the driver config is correct\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    158\u001b[39m     )\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m neo4j.exceptions.ServiceUnavailable:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    161\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not connect to Neo4j database. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    162\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure that the url is correct\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    163\u001b[39m     )\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m neo4j.exceptions.AuthError:\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    166\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not connect to Neo4j database. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure that the username and password are correct\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Could not connect to Neo4j database. Please ensure that the url is correct"
     ]
    }
   ],
   "source": [
    "from langchain_neo4j import Neo4jGraph\n",
    "\n",
    "graph = Neo4jGraph()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
